{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2002f12b",
   "metadata": {},
   "source": [
    "# HM3D Waypoint Visualization for Objectnav\n",
    "\n",
    "### Purpose\n",
    "An example of how training data for trajectory generation by a VLM is created using the [Habitat-Matterport 3D dataset](https://matterport.com/partners/meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00960ed",
   "metadata": {},
   "source": [
    "## Set up simulation\n",
    "- Load a scene from hm3d_minival_v0.2 (includes semantic annotations)\n",
    "- Set up agent sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce29a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import habitat_sim\n",
    "import magnum as mn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc97c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_graph = habitat_sim.SceneGraph()\n",
    "\n",
    "backend_cfg = habitat_sim.SimulatorConfiguration()\n",
    "backend_cfg.scene_id = \"data/ovon/versioned_data/hm3d-0.2/hm3d/train/00250-U3oQjwTuMX8/U3oQjwTuMX8.basis.glb\"\n",
    "backend_cfg.scene_dataset_config_file = \"data/ovon/versioned_data/hm3d-0.2/hm3d/hm3d_annotated_basis.scene_dataset_config.json\"\n",
    "#backend_cfg.load_semantic_mesh = True\n",
    "sensor_height = 0.5\n",
    "\n",
    "rgb_cfg = habitat_sim.CameraSensorSpec()\n",
    "rgb_cfg.uuid = \"color\"\n",
    "rgb_cfg.sensor_type = habitat_sim.SensorType.COLOR\n",
    "#rgb_cfg.hfov = mn.Deg(120)\n",
    "rgb_cfg.resolution = [1024, 1024]\n",
    "rgb_cfg.position = [0.0, sensor_height, 0.0]  # [x, y, z] relative to agent\n",
    "\n",
    "final_cfg = habitat_sim.CameraSensorSpec()\n",
    "final_cfg.uuid = \"final_color\"\n",
    "final_cfg.sensor_type = habitat_sim.SensorType.COLOR\n",
    "final_cfg.hfov = mn.Deg(120)\n",
    "final_cfg.resolution = [1024, 1024]\n",
    "final_cfg.position = [0.0, sensor_height, 0.0]  # [x, y, z] relative to agent\n",
    "\n",
    "# Semantic sensor\n",
    "sem_cfg = habitat_sim.CameraSensorSpec()\n",
    "sem_cfg.uuid = \"semantic\"\n",
    "sem_cfg.sensor_type = habitat_sim.SensorType.SEMANTIC\n",
    "#sem_cfg.hfov = mn.Deg(120)\n",
    "sem_cfg.resolution = [1024, 1024]\n",
    "sem_cfg.position = [0.0, sensor_height, 0.0]\n",
    "#\n",
    "\n",
    "# Depth sensor\n",
    "depth_cfg = habitat_sim.CameraSensorSpec()\n",
    "depth_cfg.uuid = \"depth\"\n",
    "depth_cfg.sensor_type = habitat_sim.SensorType.DEPTH\n",
    "#depth_cfg.hfov = mn.Deg(120)\n",
    "depth_cfg.resolution = [1024, 1024]\n",
    "depth_cfg.position = [0.0, sensor_height, 0.0]\n",
    "#\n",
    "\n",
    "agent_cfg = habitat_sim.agent.AgentConfiguration()\n",
    "agent_cfg.sensor_specifications = [rgb_cfg, sem_cfg, depth_cfg, final_cfg]\n",
    "\n",
    "sim_cfg = habitat_sim.Configuration(backend_cfg, [agent_cfg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81c9c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = habitat_sim.Simulator(sim_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905881eb",
   "metadata": {},
   "source": [
    "### Load navmesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c307a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051ac4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigation mesh loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "navmesh_file = \"data/ovon/versioned_data/hm3d-0.2/hm3d/train/00250-U3oQjwTuMX8/U3oQjwTuMX8.basis.navmesh\"\n",
    "\n",
    "sim.pathfinder.load_nav_mesh(navmesh_file)\n",
    "print(\"Navigation mesh loaded successfully!\")\n",
    "\n",
    "# Get a random navigable point to start\n",
    "start_point = sim.pathfinder.get_random_navigable_point()\n",
    "agent_state = habitat_sim.AgentState()\n",
    "agent_state.position = start_point\n",
    "agent_state.rotation = np.quaternion(1, 0, 0, 0)  # Identity quaternion\n",
    "sim.get_agent(0).set_state(agent_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f744fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import habitat_sim\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import magnum as mn\n",
    "import traceback\n",
    "\n",
    "def get_2d_point(sim, render_camera, point_3d):\n",
    "    # use the camera and projection matrices to transform the point onto the near plane\n",
    "    projected_point_3d = render_camera.projection_matrix.transform_point(\n",
    "        render_camera.camera_matrix.transform_point(point_3d)\n",
    "    )\n",
    "    # convert the 3D near plane point to integer pixel space\n",
    "    point_2d = mn.Vector2(projected_point_3d[0], -projected_point_3d[1])\n",
    "    point_2d = point_2d / render_camera.projection_size()[0]\n",
    "    point_2d += mn.Vector2(0.5)\n",
    "    point_2d *= render_camera.viewport\n",
    "    return mn.Vector2i(point_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2606d46",
   "metadata": {},
   "source": [
    "## Function to check if a 3D point is visible from the current camera view\n",
    "To do this:  \n",
    "    - Finds 2D projection of 3D point onto depth camera view  \n",
    "    - Checks depth at those coordinates  \n",
    "    - If depth is >= straight line distance to point, it's visible\n",
    "\n",
    "I don't know if this is actually the best way to do this -- I tried using habitat_sim.geo.Ray and checking for collisions but that didn't work well. The depth camera approach works at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90d9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import habitat_sim\n",
    "from habitat_sim.utils.common import quat_from_angle_axis\n",
    "\n",
    "def check_point_visibility_depth(sim, observer_pos, target_pos, observer_rotation=None):\n",
    "    \"\"\"\n",
    "    Checks for point visibility using the depth buffer for accurate occlusion.\n",
    "\n",
    "    Args:\n",
    "        sim: The Habitat simulator instance.\n",
    "        observer_pos (np.ndarray): Position of the observer (camera).\n",
    "        target_pos (np.ndarray): Position of the target point to check.\n",
    "        observer_rotation (quaternion): Rotation quaternion of the observer.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the target is visible, False otherwise.\n",
    "    \"\"\"\n",
    "    agent = sim.get_agent(0)\n",
    "    \n",
    "    agent_state = agent.get_state()\n",
    "    agent_state.position = observer_pos\n",
    "    if observer_rotation is not None:\n",
    "        agent_state.rotation = observer_rotation\n",
    "    agent.set_state(agent_state)\n",
    "    \n",
    "    observations = sim.get_sensor_observations()\n",
    "    \n",
    "    depth_sensor = agent._sensors.get(\"depth\")\n",
    "        \n",
    "    render_camera = depth_sensor.render_camera\n",
    "    \n",
    "    target_vec3 = mn.Vector3(target_pos[0], target_pos[1], target_pos[2])\n",
    "    \n",
    "    camera_space_point = render_camera.camera_matrix.transform_point(target_vec3)\n",
    "    \n",
    "    if camera_space_point.z > 0:\n",
    "        return False\n",
    "\n",
    "    point_2d = get_2d_point(sim, render_camera, target_vec3)\n",
    "    \n",
    "    depth_map = observations[\"depth\"]\n",
    "    height, width = depth_map.shape[:2]\n",
    "    \n",
    "    if not (0 <= point_2d.x < width and 0 <= point_2d.y < height):\n",
    "        return False\n",
    "    \n",
    "    depth_at_pixel = depth_map[point_2d.y, point_2d.x]\n",
    "    \n",
    "    # Calculate the straight-line distance from camera to target\n",
    "    # This is the actual 3D Euclidean distance\n",
    "    camera_to_target_distance = np.linalg.norm(target_pos - observer_pos)\n",
    "    \n",
    "    tolerance = 0.01  #1cm\n",
    "    \n",
    "    is_visible = depth_at_pixel >= (camera_to_target_distance - tolerance)\n",
    "    \n",
    "    return is_visible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5b24f",
   "metadata": {},
   "source": [
    "## Function to upsample waypoints along a shortest path\n",
    "Waypoints along the shortest path to a target position are often sparse. This presents some issues:  \n",
    "- Sometimes the only visible point in a trajectory is far away, which (imo) decreases how valuable that sample is for model training by decreasing the amount of points the model will use as context to improve understanding of proper trajectory generation  \n",
    "    \n",
    "- Often, when we go around a corner or down stairs, we end up with a path between two points with *no visible intermediate points*, which wrecks the continuity of a multi-turn trajectory generation problem for the model  \n",
    "  \n",
    "Take the following as an example:  \n",
    "<img src = \"traj-vis-prob.png\">\n",
    "\n",
    "We came from the path marked by the dotted yellow line, and are going to the red waypoint on the staircase. However, this waypoint is obstructed, which means we have no trajectory to generate.  \n",
    "\n",
    "To solve this, the `upsample_trajectory_waypoints` function is used to generate the blue points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e580d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def upsample_trajectory_waypoints(shortest_path, max_dist = 1):\n",
    "    \"\"\"\n",
    "    Function for upsampling the number of waypoints along a path.\n",
    "    Parameters:\n",
    "        -shortest_path: List of Magnum Vector3 (habitat_sim.nav.ShortestPath.points)\n",
    "        -max_dist (optional): Maximum distance between waypoints, default 1 meter\n",
    "    \"\"\"\n",
    "    sp = shortest_path.points\n",
    "    pointList = []\n",
    "    \n",
    "    for v1, v2 in zip(sp, sp[1:]):\n",
    "        d = (v1 - v2).length()\n",
    "        \n",
    "        pointList.append(v1)\n",
    "        \n",
    "        if d > max_dist:\n",
    "            segments = math.ceil(d / max_dist)\n",
    "            \n",
    "            #Parametric form of the line between v1 and v2\n",
    "            #L(t) = v1 + t(v2 - v1)\n",
    "            \n",
    "            for i in range(1, segments):\n",
    "                t = i / segments\n",
    "                p = v1 + (t * (v2 - v1))\n",
    "                pointList.append(p)\n",
    "    \n",
    "    pointList.append(sp[-1])\n",
    "    \n",
    "    return pointList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ea457",
   "metadata": {},
   "source": [
    "## Function to get visible trajectory at a waypoint as 2D coordinates in camera space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9259685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rotation_to_face_direction(direction_vector):\n",
    "    \"\"\"Calculate quaternion rotation to face a given direction\"\"\"\n",
    "    direction_2d = np.array([direction_vector[0], direction_vector[2]])\n",
    "    \n",
    "    if np.linalg.norm(direction_2d) < 1e-6:\n",
    "        return np.quaternion(1, 0, 0, 0)\n",
    "    \n",
    "    direction_2d = direction_2d / np.linalg.norm(direction_2d)\n",
    "    angle = np.arctan2(-direction_2d[0], -direction_2d[1])\n",
    "    \n",
    "    cos_half_angle = np.cos(angle / 2)\n",
    "    sin_half_angle = np.sin(angle / 2)\n",
    "    \n",
    "    rotation = np.quaternion(cos_half_angle, 0, sin_half_angle, 0)\n",
    "    return rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c713e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visible_trajectory(sim, shortest_path, current_waypoint_index, return_plain_view=True, return_depth_map=False):\n",
    "    \"\"\"\n",
    "    Get camera space coordinates of all visible future trajectory waypoints\n",
    "    \n",
    "    Parameters:\n",
    "        - sim: habitat sim instance\n",
    "        - shortest_path: habitat_sim.nav.ShortestPath\n",
    "        - current_waypoint_index: int\n",
    "    \n",
    "    Returns:\n",
    "        - visible_waypoints_info: List of tuples (waypoint_index, (x, y)) for visible waypoints\n",
    "        - rgb_img: RGB image (if return_plain_view is True)\n",
    "    \"\"\"\n",
    "    \n",
    "    if current_waypoint_index >= len(shortest_path.points):\n",
    "        return [], None if return_plain_view else []\n",
    "    \n",
    "    current_pos = shortest_path.points[current_waypoint_index]\n",
    "    agent = sim.get_agent(0)\n",
    "    agent_state = agent.get_state()\n",
    "    agent_state.position = current_pos\n",
    "    \n",
    "    # Calculate rotation to face next waypoint if available\n",
    "    if current_waypoint_index < len(shortest_path.points) - 1:\n",
    "        next_waypoint = shortest_path.points[current_waypoint_index + 1]\n",
    "        direction_vector = next_waypoint - current_pos\n",
    "        if np.linalg.norm(direction_vector) > 0.01:\n",
    "            agent_state.rotation = calculate_rotation_to_face_direction(direction_vector)\n",
    "    \n",
    "    agent.set_state(agent_state)\n",
    "    \n",
    "    render_camera = agent._sensors.get(\"color\").render_camera\n",
    "    \n",
    "    observations = sim.get_sensor_observations()\n",
    "    rgb_img = observations[\"color\"].copy()\n",
    "    if return_depth_map:\n",
    "        depth_img = observations[\"depth\"].copy()\n",
    "    \n",
    "    visible_waypoints_info = []\n",
    "    \n",
    "    for i in range(current_waypoint_index + 1, len(shortest_path.points)):\n",
    "        if i == current_waypoint_index:\n",
    "            continue\n",
    "            \n",
    "        waypoint = shortest_path.points[i]\n",
    "        \n",
    "        observer_rotation = agent_state.rotation\n",
    "        \n",
    "        is_visible = check_point_visibility_depth(sim, current_pos, waypoint, observer_rotation)\n",
    "        \n",
    "        if is_visible:\n",
    "            try:\n",
    "                point_2d = get_2d_point(sim, render_camera, mn.Vector3(waypoint))\n",
    "                \n",
    "                if 0 <= point_2d.x < rgb_cfg.resolution[0] and 0 <= point_2d.y < rgb_cfg.resolution[1]:\n",
    "                    visible_waypoints_info.append((i, (point_2d.x, point_2d.y)))\n",
    "            except Exception as e:\n",
    "                print(f\"Projection failed for waypoint {i}: {e}\")\n",
    "    \n",
    "    #print(visible_waypoints_info)\n",
    "    \n",
    "    if len(visible_waypoints_info) == 0 and current_waypoint_index < len(shortest_path.points) - 1:\n",
    "        next_waypoint = shortest_path.points[current_waypoint_index + 1]\n",
    "        generated_waypoint = generate_visible_waypoint_on_line(\n",
    "            sim, current_pos, next_waypoint, agent_state.rotation, render_camera\n",
    "        )\n",
    "        if generated_waypoint:\n",
    "            #print(\"~~~~~GENERATED WAYPOINT~~~~~~~~\")\n",
    "            visible_waypoints_info.append((current_waypoint_index + 1, generated_waypoint))\n",
    "    \n",
    "    if return_plain_view:\n",
    "        if return_depth_map:\n",
    "            return [visible_waypoints_info[-1]], rgb_img, depth_img\n",
    "        return [visible_waypoints_info[-1]], rgb_img\n",
    "    else:\n",
    "        return [visible_waypoints_info[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01afce3",
   "metadata": {},
   "source": [
    "## Function to generate a visible waypoint when we can't see one\n",
    "Sometimes, as a product of camera height and FOV, we can't see a point if it's right below us. This function will generate a corresponding point at the bottom edge of the camera for these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c745729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visible_waypoint_on_line(sim, start_pos, end_pos, observer_rotation, render_camera):\n",
    "    \"\"\"\n",
    "    Generate a waypoint at the edge of the camera view in the direction of the target waypoint.\n",
    "    If the target is off-screen, project a point at the camera boundary in that direction.\n",
    "    \n",
    "    Parameters:\n",
    "        - sim: habitat sim instance\n",
    "        - start_pos: starting position (current waypoint)\n",
    "        - end_pos: ending position (target waypoint)\n",
    "        - observer_rotation: rotation of the observer\n",
    "        - render_camera: camera for 2D projection\n",
    "    \n",
    "    Returns:\n",
    "        - (x, y): 2D coordinates of the generated visible waypoint at camera edge, or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First, try to project the target waypoint to see where it would be\n",
    "        target_2d = get_2d_point(sim, render_camera, mn.Vector3(end_pos))\n",
    "        \n",
    "        # Camera bounds\n",
    "        width, height = rgb_cfg.resolution[0], rgb_cfg.resolution[1]\n",
    "        \n",
    "        # If the point is already in bounds, something went wrong (shouldn't call this function)\n",
    "        if 0 <= target_2d.x < width and 0 <= target_2d.y < height:\n",
    "            return (target_2d.x, target_2d.y)\n",
    "        \n",
    "        center_x, center_y = width / 2, height / 2\n",
    "        \n",
    "        dir_x = target_2d.x - center_x\n",
    "        dir_y = target_2d.y - center_y\n",
    "        \n",
    "        # Normalize the direction\n",
    "        dir_length = np.sqrt(dir_x**2 + dir_y**2)\n",
    "        if dir_length < 1e-6:  # Avoid division by zero\n",
    "            return None\n",
    "            \n",
    "        dir_x /= dir_length\n",
    "        dir_y /= dir_length\n",
    "        \n",
    "        # Find intersection with camera boundaries\n",
    "        # Check intersection with each edge and pick the closest one\n",
    "        \n",
    "        # Right edge (x = width - 1)\n",
    "        if dir_x > 0:\n",
    "            t_right = (width - 1 - center_x) / dir_x\n",
    "            edge_y = center_y + t_right * dir_y\n",
    "            if 0 <= edge_y < height:\n",
    "                return (width - 1, int(edge_y))\n",
    "        \n",
    "        # Left edge (x = 0)\n",
    "        if dir_x < 0:\n",
    "            t_left = -center_x / dir_x\n",
    "            edge_y = center_y + t_left * dir_y\n",
    "            if 0 <= edge_y < height:\n",
    "                return (0, int(edge_y))\n",
    "        \n",
    "        # Bottom edge (y = height - 1)\n",
    "        if dir_y > 0:\n",
    "            t_bottom = (height - 1 - center_y) / dir_y\n",
    "            edge_x = center_x + t_bottom * dir_x\n",
    "            if 0 <= edge_x < width:\n",
    "                return (int(edge_x), height - 1)\n",
    "        \n",
    "        # Top edge (y = 0)\n",
    "        if dir_y < 0:\n",
    "            t_top = -center_y / dir_y\n",
    "            edge_x = center_x + t_top * dir_x\n",
    "            if 0 <= edge_x < width:\n",
    "                return (int(edge_x), 0)\n",
    "        \n",
    "        # Fallback: if no clean intersection found, clamp to nearest corner\n",
    "        edge_x = max(0, min(width - 1, center_x + dir_x * min(width, height) / 2))\n",
    "        edge_y = max(0, min(height - 1, center_y + dir_y * min(width, height) / 2))\n",
    "        \n",
    "        return (int(edge_x), int(edge_y))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to generate edge waypoint: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76515b4d",
   "metadata": {},
   "source": [
    "## Function to visualize trajectory at a waypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6493ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trajectory(sim, shortest_path, current_waypoint_index):\n",
    "    \"\"\"\n",
    "    Visualize future trajectory along waypoints\n",
    "    \n",
    "    Parameters:\n",
    "        - sim: habitat sim instance\n",
    "        - shortest_path: habitat_sim.nav.ShortestPath\n",
    "        - current_waypoint_index: int\n",
    "    \n",
    "    Returns:\n",
    "        - Image at current agent position with points visualized\n",
    "    \"\"\"\n",
    "    \n",
    "    if current_waypoint_index >= len(shortest_path.points):\n",
    "        return None\n",
    "    \n",
    "    # Get visible waypoints with their indices\n",
    "    visible_waypoints_info, rgb_img = get_visible_trajectory(sim, shortest_path, current_waypoint_index)\n",
    "    \n",
    "    if rgb_img is None:\n",
    "        return None\n",
    "        \n",
    "    rgb_with_points = rgb_img.copy()\n",
    "    \n",
    "    # Draw visible trajectory points\n",
    "    for waypoint_idx, point_2d in visible_waypoints_info:\n",
    "        # Color coding: green for next waypoint, yellow for future ones, blue for past ones\n",
    "        if waypoint_idx == current_waypoint_index + 1:\n",
    "            color = (0, 255, 0)  # Green for next waypoint\n",
    "            radius = 8\n",
    "        elif waypoint_idx > current_waypoint_index:\n",
    "            color = (0, 255, 0)  # Yellow for future waypoints\n",
    "            radius = 8\n",
    "        else:\n",
    "            color = (0, 255, 0)  # Blue for past waypoints\n",
    "            radius = 8\n",
    "        \n",
    "        # Draw circle\n",
    "        cv2.circle(rgb_with_points, point_2d, radius, color, -1)\n",
    "        cv2.circle(rgb_with_points, point_2d, radius + 2, (0, 255, 0), 1)  # White outline\n",
    "        \n",
    "        # Add waypoint number\n",
    "        cv2.putText(rgb_with_points, str(waypoint_idx), \n",
    "                   (point_2d[0] - 10, point_2d[1] - 15),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    \n",
    "    # Draw trajectory lines connecting visible points\n",
    "    if len(visible_waypoints_info) > 1:\n",
    "        # Sort by waypoint index for proper line drawing\n",
    "        sorted_waypoints = sorted(visible_waypoints_info, key=lambda x: x[0])\n",
    "        \n",
    "        for j in range(len(sorted_waypoints) - 1):\n",
    "            waypoint_idx1, pt1 = sorted_waypoints[j]\n",
    "            waypoint_idx2, pt2 = sorted_waypoints[j + 1]\n",
    "            \n",
    "            # Only connect consecutive or nearby waypoints\n",
    "            if abs(waypoint_idx2 - waypoint_idx1) <= 3:\n",
    "                cv2.line(rgb_with_points, pt1, pt2, (255, 255, 0), 2)\n",
    "    \n",
    "    return rgb_with_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b4969",
   "metadata": {},
   "source": [
    "## Function to calculate relative rotation between two positions\n",
    "So we can record where the agent faces at the end of a trajectory sequence.\n",
    "\n",
    "This allows us to teach the VLM to generate sequences of trajectories, followed by a rotation in degrees relative to its current rotation in order to continue the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e813b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quaternion\n",
    "\n",
    "def calculate_relative_rotation(from_pos, to_pos, current_rotation):\n",
    "    \n",
    "    direction = to_pos - from_pos\n",
    "    \n",
    "    direction_2d = np.array([direction[0], direction[2]])\n",
    "    direction_2d = direction_2d / np.linalg.norm(direction_2d)\n",
    "    angle = np.arctan2(-direction_2d[0], -direction_2d[1])\n",
    "    \n",
    "    current_yaw = quaternion.as_euler_angles(current_rotation)[1]\n",
    "    \n",
    "    delta_deg = np.degrees(angle - current_yaw)\n",
    "    \n",
    "    return (delta_deg + 180) % 360 - 180"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b1bda",
   "metadata": {},
   "source": [
    "## PointNav Function\n",
    "This function:\n",
    "- Calculates the shortest path to a target position\n",
    "- Navigates along the shortest path\n",
    "    - From the start position, saves a visualization, the raw RGB view, and the camera coordinates of all visible waypoints\n",
    "    - Jumps to the last visible point along the trajectory and repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "591723c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def jump_to_visible_waypoints_navigation(sim, target_pos, output_dir=\"trajectory-vis-07282025\"):\n",
    "    \"\"\"\n",
    "    Navigate by jumping to the last visible waypoint along the trajectory.\n",
    "    Saves RGB + trajectory visualizations at each jump point.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    if not sim.pathfinder.is_loaded:\n",
    "        print(\"Navigation mesh not loaded!\")\n",
    "        return\n",
    "\n",
    "    agent = sim.get_agent(0)\n",
    "    agent_state = agent.get_state()\n",
    "    start_pos = agent_state.position\n",
    "    \n",
    "    shortest_path = habitat_sim.nav.ShortestPath()\n",
    "    shortest_path.requested_start = start_pos\n",
    "    shortest_path.requested_end = target_pos\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a subdirectory for this run\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(output_dir, f\"run_{timestamp}\")\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    \n",
    "    if not sim.pathfinder.find_path(shortest_path):\n",
    "        print(\"No path found!\")\n",
    "        return run_dir, None, None, False\n",
    "\n",
    "    shortest_path.points = upsample_trajectory_waypoints(shortest_path)\n",
    "    \n",
    "    current_waypoint_idx = 0\n",
    "    jump_count = 0\n",
    "    jump_data = []\n",
    "    \n",
    "    rgb_traj_data = []\n",
    "    \n",
    "    success = False\n",
    "    \n",
    "    # Continue until we reach the final position\n",
    "    while current_waypoint_idx < len(shortest_path.points) - 1:\n",
    "        # Get visible waypoints with their indices\n",
    "        visible_waypoints_info, rgb_img, depth_img = get_visible_trajectory(sim, shortest_path, current_waypoint_idx, return_depth_map=True)\n",
    "        \n",
    "        # Extract just the 2D points for visualization\n",
    "        visible_points_2d = [(x, y) for _, (x, y) in visible_waypoints_info]\n",
    "        \n",
    "        # Create visualization\n",
    "        rgb_with_trajectory = visualize_trajectory(sim, shortest_path, current_waypoint_idx)\n",
    "        \n",
    "        future_visible_waypoints = [idx for idx, _ in visible_waypoints_info if idx > current_waypoint_idx]\n",
    "        \n",
    "        final_rotation = None\n",
    "        \n",
    "        if future_visible_waypoints:\n",
    "            last_visible_idx = max(future_visible_waypoints)\n",
    "\n",
    "            agent_state = agent.get_state()\n",
    "            current_rotation = agent_state.rotation\n",
    "\n",
    "\n",
    "            if last_visible_idx + 1 < len(shortest_path.points):\n",
    "                current_pos = shortest_path.points[current_waypoint_idx]\n",
    "                next_waypoint_pos = shortest_path.points[last_visible_idx + 1]\n",
    "                final_rotation = calculate_relative_rotation(current_pos, next_waypoint_pos, current_rotation)\n",
    "        \n",
    "        rgb_traj_data.append(rgb_with_trajectory.copy())\n",
    "        \n",
    "#         if rgb_with_trajectory is not None:\n",
    "#             # Save the visualization\n",
    "#             filename = f\"vis_jump_{jump_count:03d}_waypoint_{current_waypoint_idx:03d}.png\"\n",
    "#             filepath = os.path.join(run_dir, filename)\n",
    "#             cv2.imwrite(filepath, cv2.cvtColor(rgb_with_trajectory, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "        \n",
    "        if depth_img.ndim == 3 and depth_img.shape[2] == 1:\n",
    "            depth_img = depth_img[:, :, 0]\n",
    "\n",
    "        depth_norm = cv2.normalize(depth_img, None, alpha=0, beta=255, \n",
    "                                   norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        dfilename = f\"jump_{jump_count:03d}_waypoint_{current_waypoint_idx:03d}_depth.png\"\n",
    "        dfilepath = os.path.join(run_dir, dfilename)\n",
    "        \n",
    "        cv2.imwrite(dfilepath, depth_norm)\n",
    "        \n",
    "        rfilename = f\"jump_{jump_count:03d}_waypoint_{current_waypoint_idx:03d}.png\"\n",
    "        rfilepath = os.path.join(run_dir, rfilename)\n",
    "        cv2.imwrite(rfilepath, cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Store jump data with waypoint indices\n",
    "        visible_waypoints_data = []\n",
    "        for waypoint_idx, (x, y) in visible_waypoints_info:\n",
    "            waypoint_3d = shortest_path.points[waypoint_idx]\n",
    "            visible_waypoints_data.append({\n",
    "                \"waypoint_index\": int(waypoint_idx),\n",
    "                \"world_position\": [float(waypoint_3d[0]), float(waypoint_3d[1]), float(waypoint_3d[2])],\n",
    "                \"image_coordinates\": [int(x), int(y)]\n",
    "            })\n",
    "\n",
    "        jump_info = {\n",
    "            \"jump_number\": jump_count,\n",
    "            \"rgb_filename\": rfilename,\n",
    "            \"depth_filename\": dfilename,\n",
    "            \"from_waypoint\": current_waypoint_idx,\n",
    "            \"observer_position\": [float(shortest_path.points[current_waypoint_idx][0]), \n",
    "                                float(shortest_path.points[current_waypoint_idx][1]), \n",
    "                                float(shortest_path.points[current_waypoint_idx][2])],\n",
    "            \"visible_waypoints\": visible_waypoints_data,\n",
    "            \"total_visible\": len(visible_waypoints_info),\n",
    "        }\n",
    "\n",
    "        if final_rotation is not None:\n",
    "            jump_info[\"final_rotation\"] = final_rotation\n",
    "\n",
    "        jump_data.append(jump_info)\n",
    "        \n",
    "        \n",
    "        if not future_visible_waypoints:\n",
    "            print(f\"No visible future waypoints from position {current_waypoint_idx}. Stopping.\")\n",
    "            break\n",
    "        \n",
    "        # Jump to the last visible point\n",
    "        current_waypoint_idx = last_visible_idx\n",
    "        jump_count += 1\n",
    "        \n",
    "        # Check if we've reached the end\n",
    "        if current_waypoint_idx >= len(shortest_path.points) - 1:\n",
    "            success = True\n",
    "            break\n",
    "    \n",
    "    \n",
    "    agent = sim.get_agent(0)\n",
    "    agent_state = agent.get_state()\n",
    "\n",
    "    \n",
    "    #because we're upsampling, this puts us at most 1m away\n",
    "    agent_state.position = shortest_path.points[-2]\n",
    "    direction_vector = target_pos - agent_state.position\n",
    "    toRotate = calculate_rotation_to_face_direction(direction_vector)\n",
    "    \n",
    "    agent_state.rotation = toRotate\n",
    "    \n",
    "    agent.set_state(agent_state)\n",
    "    \n",
    "    observations = sim.get_sensor_observations()\n",
    "    final_img = observations[\"final_color\"].copy()\n",
    "\n",
    "    rgb_traj_data.append(final_img)\n",
    "    \n",
    "    \n",
    "    metadata = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"start_position\": [float(start_pos[0]), float(start_pos[1]), float(start_pos[2])],\n",
    "        \"target_position\": [float(target_pos[0]), float(target_pos[1]), float(target_pos[2])],\n",
    "        \"total_waypoints\": len(shortest_path.points),\n",
    "        \"total_jumps\": jump_count,\n",
    "        \"path_distance\": float(shortest_path.geodesic_distance),\n",
    "        \"jumps\": jump_data\n",
    "    }\n",
    "    \n",
    "#     import json\n",
    "#     metadata_file = os.path.join(run_dir, \"metadata.json\")\n",
    "#     with open(metadata_file, 'w') as f:\n",
    "#         json.dump(metadata, f, indent=2)\n",
    "    \n",
    "#     print(f\"\\nNavigation complete!\")\n",
    "#     print(f\"Total jumps: {jump_count}\")\n",
    "#     print(f\"Visualizations saved in: {run_dir}\")\n",
    "    \n",
    "    return run_dir, rgb_traj_data, metadata, success\n",
    "\n",
    "\n",
    "def test_jump_navigation(sim):\n",
    "    # Get a random navigable target point\n",
    "    target_point = sim.pathfinder.get_random_navigable_point()\n",
    "    output_dir = jump_to_visible_waypoints_navigation(sim, target_point)\n",
    "\n",
    "\n",
    "#test_jump_navigation(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a6f1e",
   "metadata": {},
   "source": [
    "## Function to save a grid of images showing the navigation sequence\n",
    "For later prompt generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "746c8a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_image_grid(traj_seq,\n",
    "                    filepath,\n",
    "                    cols=4,\n",
    "                    pixel_width=2000,\n",
    "                    pixel_height=2000,\n",
    "                    dpi=200):\n",
    "    \"\"\"\n",
    "    Save a list of images in a grid to disk at exactly pixel_width√ópixel_height.\n",
    "    \"\"\"\n",
    "    n = len(traj_seq)\n",
    "    rows = math.ceil(n / cols)\n",
    "    \n",
    "    fig_w  = pixel_width  / dpi\n",
    "    fig_h  = pixel_height / dpi\n",
    "    \n",
    "    fig, axes = plt.subplots(\n",
    "        rows, cols,\n",
    "        figsize=(fig_w, fig_h),\n",
    "        squeeze=False\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, img in enumerate(traj_seq):\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(str(idx))\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    for ax in axes[n:]:\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout(pad=0)\n",
    "    fig.savefig(filepath, dpi=dpi, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835b823",
   "metadata": {},
   "source": [
    "## ObjectNav Function\n",
    "This function uses a list of object categories present in the simulator's semantic scene to get navigable points near each object, then treats the problem as a PointNav task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5fc65",
   "metadata": {},
   "source": [
    "### Object Category List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10bf9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cats = ['appliance',\n",
    " 'bag',\n",
    " 'barbecue',\n",
    " 'basket',\n",
    " 'basket of something',\n",
    " 'bed',\n",
    " 'bed light',\n",
    " 'bed table',\n",
    " 'bedside lamp',\n",
    " 'book',\n",
    " 'book rack',\n",
    " 'cabinet',\n",
    " 'candle',\n",
    " 'cardboard box',\n",
    " 'case',\n",
    " 'chair',\n",
    " 'chest',\n",
    " 'clothes',\n",
    " 'clothes rack',\n",
    " 'computer',\n",
    " 'decoration',\n",
    " 'desk',\n",
    " 'desk chair',\n",
    " 'dining chair',\n",
    " 'dining table',\n",
    " 'dishwasher',\n",
    " 'door',\n",
    " 'door frame',\n",
    " 'dresser',\n",
    " 'flower vase',\n",
    " 'flowerpot',\n",
    " 'grill',\n",
    " 'kettle',\n",
    " 'kitchen cabinet',\n",
    " 'kitchen counter',\n",
    " 'kitchen lower cabinet',\n",
    " 'lamp',\n",
    " 'laptop',\n",
    " 'laundry machine',\n",
    " 'microwave',\n",
    " 'monitor',\n",
    " 'oven',\n",
    " 'painting',\n",
    " 'picture',\n",
    " 'pillar',\n",
    " 'pillow',\n",
    " 'plant',\n",
    " 'plunger',\n",
    " 'plush toy',\n",
    " 'pot',\n",
    " 'printer',\n",
    " 'rack',\n",
    " 'refrigerator',\n",
    " 'scale',\n",
    " 'screen',\n",
    " 'shoe',\n",
    " 'sink',\n",
    " 'sink cabinet',\n",
    " 'sofa chair',\n",
    " 'sofa seat',\n",
    " 'speaker',\n",
    " 'stool',\n",
    " 'stovetop',\n",
    " 'table',\n",
    " 'tissue box',\n",
    " 'tv',\n",
    " 'vase',\n",
    " 'wardrobe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f714d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import json\n",
    "\n",
    "\n",
    "def objectNav(sim, object_category_list):\n",
    "    for cat in object_category_list:\n",
    "        objects = [i for i in sim.semantic_scene.objects if i.category.name() == cat]\n",
    "        for obj in objects:\n",
    "            \n",
    "            start_point = sim.pathfinder.get_random_navigable_point()\n",
    "            agent_state = habitat_sim.AgentState()\n",
    "            agent_state.position = start_point\n",
    "            agent_state.rotation = np.quaternion(1, 0, 0, 0)  # Identity quaternion\n",
    "            sim.get_agent(0).set_state(agent_state)\n",
    "            \n",
    "            run_dir, traj_seq, metadata, success = jump_to_visible_waypoints_navigation(sim, obj.obb.center)#obj.aabb.center()\n",
    "            \n",
    "            #print(habitat_sim.AgentState().position - obj.aabb.center())\n",
    "            \n",
    "            if success == False:\n",
    "                shutil.rmtree(run_dir)\n",
    "                continue\n",
    "                \n",
    "            metadata['object_category'] = cat\n",
    "            \n",
    "            seq_filepath = os.path.join(run_dir, 'traj_seq.jpg')\n",
    "            \n",
    "            save_image_grid(traj_seq, seq_filepath)\n",
    "            \n",
    "            metadata['trajectory_sequence'] = seq_filepath\n",
    "            \n",
    "            metadata_file = os.path.join(run_dir, \"metadata.json\")\n",
    "            with open(metadata_file, 'w') as f:\n",
    "                json.dump(metadata, f, indent=2)\n",
    "            break #Starting with just doing one object of each category to make sure we get more scene variation per 100 episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb517b08",
   "metadata": {},
   "source": [
    "## Run it on a bunch of scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bb54b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sim(path_to_scene, path_to_config = \"data/ovon/versioned_data/hm3d-0.2/hm3d/hm3d_annotated_basis.scene_dataset_config.json\"):\n",
    "    try:\n",
    "        scene_name = path_to_scene.split('-')[-1]\n",
    "        print(scene_name)\n",
    "        scene_basis = f\"{scene_name}.basis.glb\"\n",
    "        backend_cfg = habitat_sim.SimulatorConfiguration()\n",
    "        backend_cfg.scene_id = os.path.join(path_to_scene, scene_basis)\n",
    "        backend_cfg.scene_dataset_config_file = path_to_config\n",
    "        #backend_cfg.load_semantic_mesh = True\n",
    "        sensor_height = 0.5\n",
    "\n",
    "        rgb_cfg = habitat_sim.CameraSensorSpec()\n",
    "        rgb_cfg.uuid = \"color\"\n",
    "        rgb_cfg.sensor_type = habitat_sim.SensorType.COLOR\n",
    "        #rgb_cfg.hfov = mn.Deg(120)\n",
    "        rgb_cfg.resolution = [1024, 1024]\n",
    "        rgb_cfg.position = [0.0, sensor_height, 0.0]  # [x, y, z] relative to agent\n",
    "\n",
    "        final_cfg = habitat_sim.CameraSensorSpec()\n",
    "        final_cfg.uuid = \"final_color\"\n",
    "        final_cfg.sensor_type = habitat_sim.SensorType.COLOR\n",
    "        final_cfg.hfov = mn.Deg(120)\n",
    "        final_cfg.resolution = [1024, 1024]\n",
    "        final_cfg.position = [0.0, sensor_height, 0.0]  # [x, y, z] relative to agent\n",
    "\n",
    "        # Semantic sensor\n",
    "        sem_cfg = habitat_sim.CameraSensorSpec()\n",
    "        sem_cfg.uuid = \"semantic\"\n",
    "        sem_cfg.sensor_type = habitat_sim.SensorType.SEMANTIC\n",
    "        #sem_cfg.hfov = mn.Deg(120)\n",
    "        sem_cfg.resolution = [1024, 1024]\n",
    "        sem_cfg.position = [0.0, sensor_height, 0.0]\n",
    "        #\n",
    "\n",
    "        # Depth sensor\n",
    "        depth_cfg = habitat_sim.CameraSensorSpec()\n",
    "        depth_cfg.uuid = \"depth\"\n",
    "        depth_cfg.sensor_type = habitat_sim.SensorType.DEPTH\n",
    "        #depth_cfg.hfov = mn.Deg(120)\n",
    "        depth_cfg.resolution = [1024, 1024]\n",
    "        depth_cfg.position = [0.0, sensor_height, 0.0]\n",
    "        #\n",
    "\n",
    "        agent_cfg = habitat_sim.agent.AgentConfiguration()\n",
    "        agent_cfg.sensor_specifications = [rgb_cfg, sem_cfg, depth_cfg, final_cfg]\n",
    "\n",
    "        sim_cfg = habitat_sim.Configuration(backend_cfg, [agent_cfg])\n",
    "        print(\"Built cfg\")\n",
    "\n",
    "        sim = habitat_sim.Simulator(sim_cfg)\n",
    "\n",
    "        navmesh_file = os.path.join(path_to_scene, f\"{scene_name}.basis.navmesh\")\n",
    "\n",
    "        sim.pathfinder.load_nav_mesh(navmesh_file)\n",
    "        \n",
    "        return sim\n",
    "    except Exception as e:\n",
    "        print(f\"Failed on {path_to_scene}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "426036a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "configFile = \"data/ovon/versioned_data/hm3d-0.2/hm3d/hm3d_annotated_basis.scene_dataset_config.json\"\n",
    "\n",
    "with open(configFile, 'r') as f:\n",
    "    configData = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d612454",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenesToUse = [i for i in configData['stages']['paths']['.glb'] if i[:5] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9971fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scenesToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f6f6848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train/00016-qk9eeNeR4vw/*.basis.glb',\n",
       " 'train/00017-oEPjPNSPmzL/*.basis.glb',\n",
       " 'train/00020-XYyR54sxe6b/*.basis.glb',\n",
       " 'train/00022-gmuS7Wgsbrx/*.basis.glb',\n",
       " 'train/00023-zepmXAdrpjR/*.basis.glb',\n",
       " 'train/00025-ixTj1aTMup2/*.basis.glb',\n",
       " 'train/00031-Wo6kuutE9i7/*.basis.glb',\n",
       " 'train/00033-oPj9qMxrDEa/*.basis.glb',\n",
       " 'train/00034-6imZUJGRUq4/*.basis.glb',\n",
       " 'train/00035-3XYAD64HpDr/*.basis.glb',\n",
       " 'train/00043-Jfyvj3xn2aJ/*.basis.glb',\n",
       " 'train/00055-HxmXPBbFCkH/*.basis.glb',\n",
       " 'train/00057-1UnKg1rAb8A/*.basis.glb',\n",
       " 'train/00059-kJxT5qssH4H/*.basis.glb',\n",
       " 'train/00062-ACZZiU6BXLz/*.basis.glb',\n",
       " 'train/00064-gQgtJ9Stk5s/*.basis.glb',\n",
       " 'train/00081-5biL7VEkByM/*.basis.glb',\n",
       " 'train/00087-YY8rqV6L6rf/*.basis.glb']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenesToUse[2:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72a6f135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train/00062-ACZZiU6BXLz/*.basis.glb'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenesToUse[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29afb2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm3d_root = \"data/ovon/versioned_data/hm3d-0.2/hm3d/\"\n",
    "scene_paths = [os.path.join(hm3d_root, i[:-12]) for i in scenesToUse[16:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6456d792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/ovon/versioned_data/hm3d-0.2/hm3d/train/00062-ACZZiU6BXLz',\n",
       " 'data/ovon/versioned_data/hm3d-0.2/hm3d/train/00064-gQgtJ9Stk5s',\n",
       " 'data/ovon/versioned_data/hm3d-0.2/hm3d/train/00081-5biL7VEkByM',\n",
       " 'data/ovon/versioned_data/hm3d-0.2/hm3d/train/00087-YY8rqV6L6rf',\n",
       " 'data/ovon/versioned_data/hm3d-0.2/hm3d/train/00096-6HRFAUDqpTb']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b666c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00109-GTV2Y73Sn5t\n",
      "GTV2Y73Sn5t\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00135-HeSYRw7eMtG\n",
      "HeSYRw7eMtG\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00141-iigzG1rtanx\n",
      "iigzG1rtanx\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00143-5Kw4nGdqYtS\n",
      "5Kw4nGdqYtS\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00149-UuwwmrTsfBN\n",
      "UuwwmrTsfBN\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00150-LcAd9dhvVwh\n",
      "LcAd9dhvVwh\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00155-iLDo95ZbDJq\n",
      "iLDo95ZbDJq\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00164-XfUxBGTFQQb\n",
      "XfUxBGTFQQb\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00166-RaYrxWt5pR1\n",
      "RaYrxWt5pR1\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00168-bHKTDQFJxTw\n",
      "bHKTDQFJxTw\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00172-bB6nKqfsb1z\n",
      "bB6nKqfsb1z\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00173-qZ4B7U6XE5Y\n",
      "qZ4B7U6XE5Y\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00177-VSxVP19Cdyw\n",
      "VSxVP19Cdyw\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "data/ovon/versioned_data/hm3d-0.2/hm3d/train/00179-MVVzj944atG\n",
      "MVVzj944atG\n",
      "Built cfg\n",
      "Renderer: NVIDIA GeForce RTX 3080 Ti/PCIe/SSE2 by NVIDIA Corporation\n",
      "OpenGL version: 4.6.0 NVIDIA 575.64.03\n",
      "Using optional features:\n",
      "    GL_ARB_vertex_array_object\n",
      "    GL_ARB_separate_shader_objects\n",
      "    GL_ARB_robustness\n",
      "    GL_ARB_texture_storage\n",
      "    GL_ARB_texture_view\n",
      "    GL_ARB_framebuffer_no_attachments\n",
      "    GL_ARB_invalidate_subdata\n",
      "    GL_ARB_texture_storage_multisample\n",
      "    GL_ARB_multi_bind\n",
      "    GL_ARB_direct_state_access\n",
      "    GL_ARB_get_texture_sub_image\n",
      "    GL_ARB_texture_filter_anisotropic\n",
      "    GL_KHR_debug\n",
      "    GL_KHR_parallel_shader_compile\n",
      "    GL_NV_depth_buffer_float\n",
      "Using driver workarounds:\n",
      "    no-forward-compatible-core-context\n",
      "    nv-egl-incorrect-gl11-function-pointers\n",
      "    no-layout-qualifiers-on-old-glsl\n",
      "    nv-zero-context-profile-mask\n",
      "    nv-implementation-color-read-format-dsa-broken\n",
      "    nv-cubemap-inconsistent-compressed-image-size\n",
      "    nv-cubemap-broken-full-compressed-image-query\n",
      "    nv-compressed-block-size-in-bits\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n",
      "No path found!\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "for scenepath in scene_paths[8:]:\n",
    "    print(scenepath)\n",
    "    sim = build_sim(scenepath)\n",
    "    objectNav(sim, object_cats)\n",
    "    sim.close()\n",
    "    del sim\n",
    "#     for i in range(3):\n",
    "#         gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "habitat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
